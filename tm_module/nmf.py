from tm_module.topic_modeling import TopicModeling
from tm_module.post_processing import save_topics, dominant_topics, clean_topics
from tm_module.utils.logger import Logger
from sklearn.decomposition import NMF as NMF_sklearn
from sklearn.feature_extraction.text import TfidfVectorizer
from tm_module.utils.reader import Reader


class NMF(TopicModeling):
    """Non-Negative Matrix Factorization (NMF) topic modeling algorithm.

    Args:
        reader (Reader): The reader object used to read the input data.

    Attributes:
        logger (Logger): The logger object for logging messages.

    """

    def __init__(self, reader: Reader):
        super().__init__(reader)
        self.logger = Logger('NMF').get_logger()

    def generate_representation(self):
        """
        Generate the document-term matrix representation using TF-IDF vectorization.

        """
        vectorizer = TfidfVectorizer(encoding='utf-8',
                                     analyzer='word',
                                     use_idf=True,
                                     smooth_idf=False,
                                     stop_words=None,
                                     tokenizer=lambda x: x.split(' '))
        self.matrix = vectorizer.fit_transform(self.text)
        self.vocab = vectorizer.get_feature_names_out()

    def get_topics(self, n_topics: int = 10, n_top_words: int = 10, save_path: str = ''):
        """Get the top topics generated by the NMF model.

        Args:
            n_topics (int): The number of topics to generate (default: 10).
            n_top_words (int): The number of top words to include in each topic (default: 10).
            save_path (str): The path to save the generated topics (default: '').

        Returns:
            list: A list of lists, where each inner list represents a topic and contains the top words.

        """
        topics = []
        self.logger.info("Fitting the NMF model (kullback-leibler) with tf-idf features, "
              "n_samples=%d..." % (self.n_documents))
        nmf = NMF_sklearn(n_components=n_topics, random_state=1, init="nndsvda", beta_loss="kullback-leibler",
                  solver="mu",
                  max_iter=1000,
                  alpha_W=0.00005,
                  alpha_H=0.00005,
                  l1_ratio=0.5).fit(self.matrix)

        for topic in nmf.components_:
            topics.append(
                [self.vocab[i] for i in topic.argsort()[:-(n_top_words*2) - 1:-1]]
            )

        topics = [[word for word in topic if word][:(n_top_words*2)] for topic in topics]
        topics = clean_topics(topics, n_top_words)

        if save_path:
            save_topics(topics, n_top_words, save_path)
            dominant_topics(nmf, self.matrix, save_path, self.text, self.ids)
        return topics
