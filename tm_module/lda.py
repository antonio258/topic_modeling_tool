from tm_module.topic_modeling import TopicModeling
from tm_module.post_processing import save_topics, dominant_topics
from tm_module.utils.logger import Logger
from sklearn.decomposition import LatentDirichletAllocation as LDA_sklearn
from sklearn.feature_extraction.text import CountVectorizer
from tm_module.utils.reader import Reader


class LDA(TopicModeling):
    """Latent Dirichlet Allocation (LDA) topic modeling algorithm.

    Args:
        reader (Reader): The reader object used to read the input data.

    Attributes:
        logger (Logger): The logger object for logging messages.
        matrix (scipy.sparse.csr_matrix): The document-term matrix.
        vocab (numpy.ndarray): The vocabulary of the corpus.

    """

    def __init__(self, reader: Reader):
        super().__init__(reader)
        self.logger = Logger('LDA').get_logger()

    def generate_representation(self):
        """Generate the document-term matrix and vocabulary.

        This method uses the CountVectorizer to convert the input text into a document-term matrix.
        The vocabulary is extracted from the vectorizer.

        """
        vectorizer = CountVectorizer(encoding='utf-8',
                                     analyzer='word',
                                     stop_words=None,
                                     tokenizer=lambda x: x.split(' '))
        self.matrix = vectorizer.fit_transform(self.text)
        self.vocab = vectorizer.get_feature_names_out()

    def get_topics(self, n_topics: int = 10, n_top_words: int = 10, save_path: str = ''):
        """Get the top words for each topic generated by the LDA model.

        Args:
            n_topics (int): The number of topics to generate (default: 10).
            n_top_words (int): The number of top words to retrieve for each topic (default: 10).
            save_path (str): The path to save the generated topics (default: '').

        Returns:
            list: A list of lists, where each inner list contains the top words for a topic.

        """
        topics = []
        self.logger.info("Fitting LDA models with tf features, n_samples=%d..." % (self.n_documents))
        lda = LDA_sklearn(
            n_components=n_topics,
            learning_method="online",
            n_jobs=12,
            batch_size=528,
            max_iter=5,
            learning_offset=5.0,
            random_state=0,
        )
        lda.fit(self.matrix)

        for topic in lda.components_:
            topics.append(
                [self.vocab[i] for i in topic.argsort()[:-(n_top_words*2) - 1:-1]]
            )

        topics = [[word for word in topic if word][:n_top_words] for topic in topics]
        if save_path:
            save_topics(topics, n_top_words, save_path)
            dominant_topics(lda, self.matrix, save_path, self.text, self.ids)
        return topics
